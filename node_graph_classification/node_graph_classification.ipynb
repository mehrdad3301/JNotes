{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **CS224W - Colab 2**","metadata":{"id":"XuXWJLEm2UWS"}},{"cell_type":"markdown","source":"In Colab 2, we will work to construct our own graph neural network using PyTorch Geometric (PyG) and then apply that model on two Open Graph Benchmark (OGB) datasets. These two datasets will be used to benchmark your model's performance on two different graph-based tasks: 1) node property prediction, predicting properties of single nodes and 2) graph property prediction, predicting properties of entire graphs or subgraphs.\n\nFirst, we will learn how PyTorch Geometric stores graphs as PyTorch tensors.\n\nThen, we will load and inspect one of the Open Graph Benchmark (OGB) datasets by using the `ogb` package. OGB is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. The `ogb` package not only provides data loaders for each dataset but also model evaluators.\n\nLastly, we will build our own graph neural network using PyTorch Geometric. We will then train and evaluate our model on the OGB node property prediction and graph property prediction tasks.\n\n**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell\n\nWe recommend you save a copy of this colab in your drive so you don't lose progress!\n\nHave fun and good luck on Colab 2 :)","metadata":{"id":"8gzsP50bF6Gb"}},{"cell_type":"markdown","source":"# Device\nYou might need to use a GPU for this Colab to run quickly.\n\nPlease click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**.","metadata":{"id":"ZGKqVEbbMEzf"}},{"cell_type":"code","source":"","metadata":{"id":"pi_CBJyUg6jk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup\nAs discussed in Colab 0, the installation of PyG on Colab can be a little bit tricky. First let us check which version of PyTorch you are running","metadata":{"id":"OCK7krJdp4o8"}},{"cell_type":"code","source":"import torch\nimport os\nprint(\"PyTorch has version {}\".format(torch.__version__))","metadata":{"id":"2vkP8pA1qBE5","outputId":"7fdf3114-4f2c-4a22-af71-c999c6d6ab77","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T19:19:50.363570Z","iopub.execute_input":"2024-02-14T19:19:50.363931Z","iopub.status.idle":"2024-02-14T19:19:54.529300Z","shell.execute_reply.started":"2024-02-14T19:19:50.363898Z","shell.execute_reply":"2024-02-14T19:19:54.528320Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"PyTorch has version 2.1.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Download the necessary packages for PyG. Make sure that your version of torch matches the output from the cell above. In case of any issues, more information can be found on the [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html).","metadata":{"id":"L6d22O6DqGSZ"}},{"cell_type":"code","source":"# Install torch geometric\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n  !pip install torch-geometric\n  !pip install ogb","metadata":{"id":"zr8hfxJ-qRg2","outputId":"c92c1e91-2a5f-4ea3-a3a6-8884ace39978","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T19:21:05.866517Z","iopub.execute_input":"2024-02-14T19:21:05.867469Z","iopub.status.idle":"2024-02-14T19:47:32.754085Z","shell.execute_reply.started":"2024-02-14T19:21:05.867439Z","shell.execute_reply":"2024-02-14T19:47:32.752970Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\nCollecting torch-scatter\n  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: torch-scatter\n  Building wheel for torch-scatter (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=3765625 sha256=bdea6635a5aa8c1fd3045bfa15eb432de0a3f94bafd57a9b4792596ceb3bb5d4\n  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\nSuccessfully built torch-scatter\nInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.2\nLooking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\nCollecting torch-sparse\n  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-sparse) (1.11.4)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->torch-sparse) (1.24.4)\nBuilding wheels for collected packages: torch-sparse\n  Building wheel for torch-sparse (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=2626765 sha256=da7544ae6417ec5a09ec7dff182b4ca88a52386f06b659d233f82f3c240fef54\n  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\nSuccessfully built torch-sparse\nInstalling collected packages: torch-sparse\nSuccessfully installed torch-sparse-0.6.18\nCollecting torch-geometric\n  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.24.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.4)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (2.31.0)\nRequirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.1.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch-geometric) (2023.11.17)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\nDownloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.4.0\nCollecting ogb\n  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (2.1.2)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (1.24.4)\nRequirement already satisfied: tqdm>=4.29.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (4.66.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (1.2.2)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (2.1.4)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (1.16.0)\nRequirement already satisfied: urllib3>=1.24.0 in /opt/conda/lib/python3.10/site-packages (from ogb) (1.26.18)\nCollecting outdated>=0.2.0 (from ogb)\n  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\nRequirement already satisfied: setuptools>=44 in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (69.0.3)\nCollecting littleutils (from outdated>=0.2.0->ogb)\n  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (2.31.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2023.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\nBuilding wheels for collected packages: littleutils\n  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=4e25587001770c4c2b63ecf14b8eaf3caab3c30d1478fd613229fd1796b374b0\n  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\nSuccessfully built littleutils\nInstalling collected packages: littleutils, outdated, ogb\nSuccessfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1) PyTorch Geometric (Datasets and Data)\n","metadata":{"id":"Nwwq0nSdmsOL"}},{"cell_type":"markdown","source":"PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors.\n\nIn this section, we will learn how to use `torch_geometric.datasets` and `torch_geometric.data` together.","metadata":{"id":"Sf7vUmdNKCjA"}},{"cell_type":"markdown","source":"## PyG Datasets\n\nThe `torch_geometric.datasets` class has many common graph datasets. Here we will explore its usage through one example dataset.","metadata":{"id":"ic-o1P3r6hr2"}},{"cell_type":"code","source":"from torch_geometric.datasets import TUDataset\n\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  root = './enzymes'\n  name = 'ENZYMES'\n\n  # The ENZYMES dataset\n  pyg_dataset= TUDataset(root, name)\n\n  # You will find that there are 600 graphs in this dataset\n  print(pyg_dataset)","metadata":{"id":"zT5qca3x6XpG","outputId":"d97e2a6d-dd28-4786-a45f-75540620d84c","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T19:48:05.176296Z","iopub.execute_input":"2024-02-14T19:48:05.177021Z","iopub.status.idle":"2024-02-14T19:48:10.024859Z","shell.execute_reply.started":"2024-02-14T19:48:05.176985Z","shell.execute_reply":"2024-02-14T19:48:10.023658Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\nExtracting enzymes/ENZYMES/ENZYMES.zip\nProcessing...\n","output_type":"stream"},{"name":"stdout","text":"ENZYMES(600)\n","output_type":"stream"},{"name":"stderr","text":"Done!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Question 1: What is the number of classes and number of features in the ENZYMES dataset? (5 points)","metadata":{"id":"NLm5vVYMAP2x"}},{"cell_type":"code","source":"def get_num_classes(pyg_dataset):\n  # TODO: Implement a function that takes a PyG dataset object\n  # and returns the number of classes for that dataset.\n\n  return pyg_dataset.num_classes\n\ndef get_num_features(pyg_dataset):\n  # TODO: Implement a function that takes a PyG dataset object\n  # and returns the number of features for that dataset.\n\n  return pyg_dataset.num_features\n\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  num_classes = get_num_classes(pyg_dataset)\n  num_features = get_num_features(pyg_dataset)\n  print(\"{} dataset has {} classes\".format(name, num_classes))\n  print(\"{} dataset has {} features\".format(name, num_features))","metadata":{"id":"8iF_Kyqr_JbY","outputId":"a63a406d-ada1-49d5-bf06-22fcb94eed7a","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T19:48:10.026593Z","iopub.execute_input":"2024-02-14T19:48:10.027547Z","iopub.status.idle":"2024-02-14T19:48:10.034679Z","shell.execute_reply.started":"2024-02-14T19:48:10.027521Z","shell.execute_reply":"2024-02-14T19:48:10.033621Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"ENZYMES dataset has 6 classes\nENZYMES dataset has 3 features\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## PyG Data\n\nEach PyG dataset stores a list of `torch_geometric.data.Data` objects, where each `torch_geometric.data.Data` object represents a graph. We can easily get the `Data` object by indexing into the dataset.\n\nFor more information such as what is stored in the `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data).","metadata":{"id":"rwKbzhHUAckZ"}},{"cell_type":"markdown","source":"## Question 2: What is the label of the graph with index 100 in the ENZYMES dataset? (5 points)","metadata":{"id":"7sCV3xJWCddX"}},{"cell_type":"code","source":"def get_graph_class(pyg_dataset, idx):\n  # TODO: Implement a function that takes a PyG dataset object,\n  # an index of a graph within the dataset, and returns the class/label\n  # of the graph (as an integer).\n\n  return pyg_dataset.get(idx)['y']\n\n# Here pyg_dataset is a dataset for graph classification\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  graph_0 = pyg_dataset[0]\n  print(graph_0)\n  idx = 100\n  label = get_graph_class(pyg_dataset, idx)\n  print('Graph with index {} has label {}'.format(idx, label))","metadata":{"id":"LIis9oTZAfs3","outputId":"58fe51f6-ebac-4a61-f9c6-4b8c768487d7","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T19:48:15.001071Z","iopub.execute_input":"2024-02-14T19:48:15.001440Z","iopub.status.idle":"2024-02-14T19:48:15.009238Z","shell.execute_reply.started":"2024-02-14T19:48:15.001411Z","shell.execute_reply":"2024-02-14T19:48:15.008367Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Data(edge_index=[2, 168], x=[37, 3], y=[1])\nGraph with index 100 has label tensor([4])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Question 3: How many edges does the graph with index 200 have? (5 points)","metadata":{"id":"fKhcVeAhCwoY"}},{"cell_type":"code","source":"def get_graph_num_edges(pyg_dataset, idx):\n  # TODO: Implement a function that takes a PyG dataset object,\n  # the index of a graph in the dataset, and returns the number of\n  # edges in the graph (as an integer). You should not count an edge\n  # twice if the graph is undirected. For example, in an undirected\n  # graph G, if two nodes v and u are connected by an edge, this edge\n  # should only be counted once.\n\n  return pyg_dataset.get(idx)['edge_index'].shape[1]\n\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  idx = 200\n  num_edges = get_graph_num_edges(pyg_dataset, idx)\n  print('Graph with index {} has {} edges'.format(idx, num_edges))","metadata":{"id":"f5m2DOfhBtWv","outputId":"51d10b65-9000-43af-d5d6-034242472385","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T19:48:16.279525Z","iopub.execute_input":"2024-02-14T19:48:16.279910Z","iopub.status.idle":"2024-02-14T19:48:16.286958Z","shell.execute_reply.started":"2024-02-14T19:48:16.279879Z","shell.execute_reply":"2024-02-14T19:48:16.286042Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Graph with index 200 has 106 edges\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2) Open Graph Benchmark (OGB)\n\nThe Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can then be evaluated by using the OGB Evaluator in a unified manner.","metadata":{"id":"AXa7yIG4E0Fp"}},{"cell_type":"markdown","source":"## Dataset and Data\n\nOGB also supports PyG dataset and data classes. Here we take a look on the `ogbn-arxiv` dataset.","metadata":{"id":"HnazPGGAJAZN"}},{"cell_type":"code","source":"import torch_geometric.transforms as T\nfrom ogb.nodeproppred import PygNodePropPredDataset\n\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  dataset_name = 'ogbn-arxiv'\n  # Load the dataset and transform it to sparse tensor\n  dataset = PygNodePropPredDataset(name=dataset_name,\n                                  transform=T.ToSparseTensor())\n  print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n\n  # Extract the graph\n  data = dataset[0]\n  print(data)","metadata":{"id":"Gpc6bTm3GF02","outputId":"3aa5d4e1-a8cb-490a-f899-086610837fe1","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T19:58:27.998270Z","iopub.execute_input":"2024-02-14T19:58:27.999258Z","iopub.status.idle":"2024-02-14T19:58:46.378057Z","shell.execute_reply.started":"2024-02-14T19:58:27.999226Z","shell.execute_reply":"2024-02-14T19:58:46.377036Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"ogbn-arxiv has been updated.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Will you update the dataset now? (y/N)\n y\n"},{"name":"stdout","text":"Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n","output_type":"stream"},{"name":"stderr","text":"Downloaded 0.08 GB: 100%|██████████| 81/81 [00:09<00:00,  8.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/arxiv.zip\n","output_type":"stream"},{"name":"stderr","text":"Processing...\n","output_type":"stream"},{"name":"stdout","text":"Loading necessary files...\nThis might take a while.\nProcessing graphs...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 8811.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Converting graphs into PyG objects...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 3908.95it/s]","output_type":"stream"},{"name":"stdout","text":"Saving...\nThe ogbn-arxiv dataset has 1 graph\n","output_type":"stream"},{"name":"stderr","text":"\nDone!\n","output_type":"stream"},{"name":"stdout","text":"Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=1166243])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Question 4: How many features are in the ogbn-arxiv graph? (5 points)","metadata":{"id":"Cw0xZJKZI-n3"}},{"cell_type":"code","source":"def graph_num_features(data):\n  # TODO: Implement a function that takes a PyG data object,\n  # and returns the number of features in the graph (as an integer).\n  return data.num_features\n\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  num_features = graph_num_features(data)\n  print('The graph has {} features'.format(num_features))","metadata":{"id":"ZP844_nT2ZJl","outputId":"733c934a-91b9-4801-bac4-8ad9b36b514b","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T20:03:07.566258Z","iopub.execute_input":"2024-02-14T20:03:07.567072Z","iopub.status.idle":"2024-02-14T20:03:07.572425Z","shell.execute_reply.started":"2024-02-14T20:03:07.567043Z","shell.execute_reply":"2024-02-14T20:03:07.571472Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"The graph has 128 features\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3) GNN: Node Property Prediction\n\nIn this section we will build our first graph neural network using PyTorch Geometric. Then we will apply it to the task of node property prediction (node classification).\n\nSpecifically, we will use GCN as the foundation for your graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer.","metadata":{"id":"9DP_yEQZ0NVW"}},{"cell_type":"markdown","source":"## Setup","metadata":{"id":"O4CcOUEoInjD"}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport torch.nn.functional as F\nprint(torch.__version__)\n\n# The PyG built-in GCNConv\nfrom torch_geometric.nn import GCNConv\n\nimport torch_geometric.transforms as T\nfrom ogb.nodeproppred import PygNodePropPredDataset, Evaluator","metadata":{"id":"-DCtgcHpGIpd","outputId":"de15b798-1ff5-4856-c6be-daf29071d5d6","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-02-14T20:03:10.720126Z","iopub.execute_input":"2024-02-14T20:03:10.721003Z","iopub.status.idle":"2024-02-14T20:03:10.726428Z","shell.execute_reply.started":"2024-02-14T20:03:10.720971Z","shell.execute_reply":"2024-02-14T20:03:10.725499Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"2.1.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load and Preprocess the Dataset","metadata":{"id":"0IK9z0wQIwzQ"}},{"cell_type":"code","source":"if 'IS_GRADESCOPE_ENV' not in os.environ:\n  dataset_name = 'ogbn-arxiv'\n  dataset = PygNodePropPredDataset(name=dataset_name,\n                                  transform=T.ToSparseTensor())\n  data = dataset[0]\n\n  # Make the adjacency matrix to symmetric\n  data.adj_t = data.adj_t.to_symmetric()\n\n  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n  # If you use GPU, the device should be cuda\n  print('Device: {}'.format(device))\n\n  data = data.to(device)\n  split_idx = dataset.get_idx_split()\n  train_idx = split_idx['train'].to(device)","metadata":{"id":"0ibJ0ieoIwQM","outputId":"f193387b-897b-414e-f8d5-5e5c7ad8ca12","colab":{"base_uri":"https://localhost:8080/","height":255},"execution":{"iopub.status.busy":"2024-02-14T20:03:12.059518Z","iopub.execute_input":"2024-02-14T20:03:12.059895Z","iopub.status.idle":"2024-02-14T20:03:12.658360Z","shell.execute_reply.started":"2024-02-14T20:03:12.059867Z","shell.execute_reply":"2024-02-14T20:03:12.657425Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## GCN Model\n\nNow we will implement our GCN model!\n\nPlease follow the figure below to implement the `forward` function.\n\n\n![test](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)","metadata":{"id":"OgUA815bNJ8w"}},{"cell_type":"code","source":"class GCN(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n                 dropout, return_embeds=False):\n        # TODO: Implement a function that initializes self.convs,\n        # self.bns, and self.softmax.\n\n        super(GCN, self).__init__()\n\n        # A list of GCNConv layers\n        self.convs = torch.nn.ModuleList([GCNConv(input_dim, hidden_dim)] +  \n                                         [GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers - 2)] + \n                                         [GCNConv(hidden_dim, output_dim)])\n\n        # A list of 1D batch normalization layers\n        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n\n        # The log softmax layer\n        self.softmax = torch.nn.LogSoftmax(dim=-1)\n        \n        # Probability of an element getting zeroed\n        self.dropout = dropout\n\n        # Skip classification layer and return node embeddings\n        self.return_embeds = return_embeds\n\n    def reset_parameters(self):\n        for conv in self.convs:\n            conv.reset_parameters()\n        for bn in self.bns:\n            bn.reset_parameters()\n\n    def forward(self, x, adj_t):\n        # TODO: Implement a function that takes the feature tensor x and\n        # edge_index tensor adj_t and returns the output tensor as\n        # shown in the figure.\n        \n        out = x \n        for i, l in enumerate(self.convs): \n            if i == len(self.convs) - 1: \n                break \n            out = self.convs[i](out, adj_t)\n            out = self.bns[i](out) \n            out = torch.nn.functional.relu(out) \n            out = torch.nn.functional.dropout(out, p=self.dropout, training = self.training) \n            \n        out = self.convs[-1](out, adj_t)\n        \n        if not self.return_embeds: \n            out = self.softmax(out) \n            \n        return out","metadata":{"id":"IgspXTYpNJLA","execution":{"iopub.status.busy":"2024-02-14T20:05:09.396157Z","iopub.execute_input":"2024-02-14T20:05:09.397085Z","iopub.status.idle":"2024-02-14T20:05:09.409381Z","shell.execute_reply.started":"2024-02-14T20:05:09.397050Z","shell.execute_reply":"2024-02-14T20:05:09.408402Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train(model, data, train_idx, optimizer, loss_fn):\n    # TODO: Implement a function that trains the model by\n    # using the given optimizer and loss_fn.\n    loss = 0\n\n    optimizer.zero_grad()\n    out = model(data.x, data.adj_t)\n    loss = loss_fn(out[train_idx], data.y[train_idx].squeeze())\n    \n    loss.backward()\n    optimizer.step()\n\n    return loss.item()","metadata":{"id":"FF1hnHUhO81e","execution":{"iopub.status.busy":"2024-02-14T20:09:11.785620Z","iopub.execute_input":"2024-02-14T20:09:11.786019Z","iopub.status.idle":"2024-02-14T20:09:11.791715Z","shell.execute_reply.started":"2024-02-14T20:09:11.785993Z","shell.execute_reply":"2024-02-14T20:09:11.790786Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Test function here\n@torch.no_grad()\ndef test(model, data, split_idx, evaluator, save_model_results=False):\n    # TODO: Implement a function that tests the model by\n    # using the given split_idx and evaluator.\n    model.eval()\n\n    # The output of model on all data\n    out = model.forward(data.x, data.adj_t)\n    \n    y_pred = out.argmax(dim=-1, keepdim=True)\n\n    train_acc = evaluator.eval({\n        'y_true': data.y[split_idx['train']],\n        'y_pred': y_pred[split_idx['train']],\n    })['acc']\n    valid_acc = evaluator.eval({\n        'y_true': data.y[split_idx['valid']],\n        'y_pred': y_pred[split_idx['valid']],\n    })['acc']\n    test_acc = evaluator.eval({\n        'y_true': data.y[split_idx['test']],\n        'y_pred': y_pred[split_idx['test']],\n    })['acc']\n\n    if save_model_results:\n      print (\"Saving Model Predictions\")\n\n      data = {}\n      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n\n      df = pd.DataFrame(data=data)\n      # Save locally as csv\n      df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n\n\n    return train_acc, valid_acc, test_acc","metadata":{"id":"aJdlrJQhPBsK","execution":{"iopub.status.busy":"2024-02-14T20:09:12.242745Z","iopub.execute_input":"2024-02-14T20:09:12.243496Z","iopub.status.idle":"2024-02-14T20:09:12.252480Z","shell.execute_reply.started":"2024-02-14T20:09:12.243465Z","shell.execute_reply":"2024-02-14T20:09:12.251521Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Please do not change the args\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  args = {\n      'device': device,\n      'num_layers': 3,\n      'hidden_dim': 256,\n      'dropout': 0.5,\n      'lr': 0.01,\n      'epochs': 100,\n  }\n  args","metadata":{"id":"o7F46xkuLiOL","outputId":"d27a8df7-7b62-4e1d-f851-41159464076a","colab":{"base_uri":"https://localhost:8080/","height":255},"execution":{"iopub.status.busy":"2024-02-14T20:09:13.414000Z","iopub.execute_input":"2024-02-14T20:09:13.414671Z","iopub.status.idle":"2024-02-14T20:09:13.419463Z","shell.execute_reply.started":"2024-02-14T20:09:13.414617Z","shell.execute_reply":"2024-02-14T20:09:13.418586Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"if 'IS_GRADESCOPE_ENV' not in os.environ:\n  model = GCN(data.num_features, args['hidden_dim'],\n              dataset.num_classes, args['num_layers'],\n              args['dropout']).to(device)\n  evaluator = Evaluator(name='ogbn-arxiv')","metadata":{"id":"dT8RyM2cPGxM","execution":{"iopub.status.busy":"2024-02-14T20:09:13.699804Z","iopub.execute_input":"2024-02-14T20:09:13.700503Z","iopub.status.idle":"2024-02-14T20:09:13.713296Z","shell.execute_reply.started":"2024-02-14T20:09:13.700475Z","shell.execute_reply":"2024-02-14T20:09:13.712265Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Please do not change these args\n# Training should take <10min using GPU runtime\nimport copy\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  # reset the parameters to initial random value\n  model.reset_parameters()\n\n  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n  loss_fn = F.nll_loss\n\n  best_model = None\n  best_valid_acc = 0\n\n  for epoch in range(1, 1 + args[\"epochs\"]):\n    loss = train(model, data, train_idx, optimizer, loss_fn)\n    result = test(model, data, split_idx, evaluator)\n    train_acc, valid_acc, test_acc = result\n    if valid_acc > best_valid_acc:\n        best_valid_acc = valid_acc\n        best_model = copy.deepcopy(model)\n    print(f'Epoch: {epoch:02d}, '\n          f'Loss: {loss:.4f}, '\n          f'Train: {100 * train_acc:.2f}%, '\n          f'Valid: {100 * valid_acc:.2f}% '\n          f'Test: {100 * test_acc:.2f}%')","metadata":{"id":"qd5O5cnPPdVF","execution":{"iopub.status.busy":"2024-02-14T20:09:15.021153Z","iopub.execute_input":"2024-02-14T20:09:15.021784Z","iopub.status.idle":"2024-02-14T20:09:28.594022Z","shell.execute_reply.started":"2024-02-14T20:09:15.021751Z","shell.execute_reply":"2024-02-14T20:09:28.593097Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch: 01, Loss: 4.0220, Train: 19.41%, Valid: 25.93% Test: 23.50%\nEpoch: 02, Loss: 3.4098, Train: 24.84%, Valid: 23.86% Test: 21.66%\nEpoch: 03, Loss: 3.0317, Train: 29.43%, Valid: 30.88% Test: 27.65%\nEpoch: 04, Loss: 2.9067, Train: 31.90%, Valid: 29.05% Test: 31.45%\nEpoch: 05, Loss: 2.8172, Train: 36.58%, Valid: 35.14% Test: 31.02%\nEpoch: 06, Loss: 2.6102, Train: 30.90%, Valid: 31.42% Test: 28.12%\nEpoch: 07, Loss: 2.5372, Train: 37.29%, Valid: 40.51% Test: 39.91%\nEpoch: 08, Loss: 2.4013, Train: 41.07%, Valid: 43.61% Test: 42.89%\nEpoch: 09, Loss: 2.3609, Train: 44.14%, Valid: 46.77% Test: 45.68%\nEpoch: 10, Loss: 2.2295, Train: 42.17%, Valid: 38.42% Test: 35.14%\nEpoch: 11, Loss: 2.1786, Train: 45.49%, Valid: 41.88% Test: 38.99%\nEpoch: 12, Loss: 2.0970, Train: 49.86%, Valid: 54.10% Test: 56.24%\nEpoch: 13, Loss: 2.0390, Train: 51.39%, Valid: 54.63% Test: 53.70%\nEpoch: 14, Loss: 1.9655, Train: 50.53%, Valid: 50.54% Test: 47.98%\nEpoch: 15, Loss: 1.9229, Train: 51.90%, Valid: 52.63% Test: 50.32%\nEpoch: 16, Loss: 1.8656, Train: 54.15%, Valid: 57.48% Test: 56.61%\nEpoch: 17, Loss: 1.8147, Train: 54.52%, Valid: 57.33% Test: 56.42%\nEpoch: 18, Loss: 1.7711, Train: 54.15%, Valid: 53.67% Test: 50.98%\nEpoch: 19, Loss: 1.7342, Train: 56.44%, Valid: 56.13% Test: 53.16%\nEpoch: 20, Loss: 1.6905, Train: 57.28%, Valid: 60.05% Test: 59.98%\nEpoch: 21, Loss: 1.6510, Train: 58.07%, Valid: 60.30% Test: 59.38%\nEpoch: 22, Loss: 1.6052, Train: 58.09%, Valid: 57.83% Test: 54.73%\nEpoch: 23, Loss: 1.5832, Train: 58.68%, Valid: 59.84% Test: 57.76%\nEpoch: 24, Loss: 1.5494, Train: 59.56%, Valid: 61.17% Test: 60.37%\nEpoch: 25, Loss: 1.5229, Train: 59.86%, Valid: 59.69% Test: 57.48%\nEpoch: 26, Loss: 1.4919, Train: 60.69%, Valid: 61.97% Test: 60.76%\nEpoch: 27, Loss: 1.4610, Train: 60.71%, Valid: 61.49% Test: 59.69%\nEpoch: 28, Loss: 1.4449, Train: 60.55%, Valid: 60.86% Test: 58.48%\nEpoch: 29, Loss: 1.4377, Train: 61.39%, Valid: 63.00% Test: 62.43%\nEpoch: 30, Loss: 1.4105, Train: 61.72%, Valid: 62.34% Test: 60.54%\nEpoch: 31, Loss: 1.3878, Train: 61.99%, Valid: 61.39% Test: 59.20%\nEpoch: 32, Loss: 1.3784, Train: 62.05%, Valid: 63.38% Test: 62.79%\nEpoch: 33, Loss: 1.3579, Train: 62.22%, Valid: 62.05% Test: 59.49%\nEpoch: 34, Loss: 1.3506, Train: 62.63%, Valid: 63.56% Test: 62.80%\nEpoch: 35, Loss: 1.3357, Train: 63.19%, Valid: 63.68% Test: 62.25%\nEpoch: 36, Loss: 1.3137, Train: 63.12%, Valid: 63.12% Test: 61.19%\nEpoch: 37, Loss: 1.3109, Train: 63.32%, Valid: 63.92% Test: 62.79%\nEpoch: 38, Loss: 1.3003, Train: 63.74%, Valid: 63.34% Test: 61.28%\nEpoch: 39, Loss: 1.2878, Train: 63.73%, Valid: 64.51% Test: 63.13%\nEpoch: 40, Loss: 1.2801, Train: 64.18%, Valid: 65.08% Test: 64.43%\nEpoch: 41, Loss: 1.2674, Train: 64.28%, Valid: 63.95% Test: 61.80%\nEpoch: 42, Loss: 1.2650, Train: 64.49%, Valid: 65.13% Test: 63.40%\nEpoch: 43, Loss: 1.2490, Train: 64.52%, Valid: 64.82% Test: 63.25%\nEpoch: 44, Loss: 1.2455, Train: 64.89%, Valid: 64.50% Test: 62.62%\nEpoch: 45, Loss: 1.2391, Train: 65.16%, Valid: 65.80% Test: 64.97%\nEpoch: 46, Loss: 1.2311, Train: 65.09%, Valid: 65.49% Test: 63.69%\nEpoch: 47, Loss: 1.2246, Train: 65.32%, Valid: 65.45% Test: 63.65%\nEpoch: 48, Loss: 1.2153, Train: 65.39%, Valid: 65.79% Test: 64.76%\nEpoch: 49, Loss: 1.2125, Train: 65.49%, Valid: 65.59% Test: 63.80%\nEpoch: 50, Loss: 1.2089, Train: 65.31%, Valid: 65.54% Test: 64.39%\nEpoch: 51, Loss: 1.2109, Train: 65.10%, Valid: 65.92% Test: 65.02%\nEpoch: 52, Loss: 1.2182, Train: 64.74%, Valid: 65.20% Test: 63.68%\nEpoch: 53, Loss: 1.2273, Train: 65.40%, Valid: 66.23% Test: 65.13%\nEpoch: 54, Loss: 1.2033, Train: 66.15%, Valid: 66.62% Test: 66.05%\nEpoch: 55, Loss: 1.1776, Train: 65.77%, Valid: 65.68% Test: 64.06%\nEpoch: 56, Loss: 1.1889, Train: 66.00%, Valid: 66.44% Test: 65.22%\nEpoch: 57, Loss: 1.1846, Train: 66.50%, Valid: 66.86% Test: 66.18%\nEpoch: 58, Loss: 1.1649, Train: 66.32%, Valid: 66.21% Test: 64.71%\nEpoch: 59, Loss: 1.1697, Train: 66.64%, Valid: 66.88% Test: 65.76%\nEpoch: 60, Loss: 1.1587, Train: 66.87%, Valid: 67.34% Test: 66.95%\nEpoch: 61, Loss: 1.1553, Train: 66.70%, Valid: 66.46% Test: 65.16%\nEpoch: 62, Loss: 1.1522, Train: 67.07%, Valid: 66.72% Test: 65.14%\nEpoch: 63, Loss: 1.1410, Train: 67.05%, Valid: 67.73% Test: 67.41%\nEpoch: 64, Loss: 1.1454, Train: 67.36%, Valid: 67.04% Test: 65.36%\nEpoch: 65, Loss: 1.1325, Train: 67.21%, Valid: 67.00% Test: 65.68%\nEpoch: 66, Loss: 1.1316, Train: 67.48%, Valid: 67.78% Test: 67.45%\nEpoch: 67, Loss: 1.1278, Train: 67.69%, Valid: 67.49% Test: 66.00%\nEpoch: 68, Loss: 1.1222, Train: 67.48%, Valid: 67.53% Test: 66.61%\nEpoch: 69, Loss: 1.1210, Train: 67.75%, Valid: 67.54% Test: 66.37%\nEpoch: 70, Loss: 1.1160, Train: 67.69%, Valid: 67.95% Test: 67.06%\nEpoch: 71, Loss: 1.1157, Train: 67.64%, Valid: 67.16% Test: 65.57%\nEpoch: 72, Loss: 1.1194, Train: 67.22%, Valid: 67.66% Test: 67.37%\nEpoch: 73, Loss: 1.1296, Train: 67.03%, Valid: 65.88% Test: 63.22%\nEpoch: 74, Loss: 1.1374, Train: 67.21%, Valid: 67.67% Test: 67.45%\nEpoch: 75, Loss: 1.1293, Train: 68.12%, Valid: 67.06% Test: 64.86%\nEpoch: 76, Loss: 1.1017, Train: 68.15%, Valid: 67.87% Test: 66.53%\nEpoch: 77, Loss: 1.0981, Train: 67.85%, Valid: 67.94% Test: 67.37%\nEpoch: 78, Loss: 1.1078, Train: 68.11%, Valid: 67.03% Test: 64.78%\nEpoch: 79, Loss: 1.0979, Train: 68.36%, Valid: 68.24% Test: 67.42%\nEpoch: 80, Loss: 1.0903, Train: 68.28%, Valid: 68.10% Test: 67.08%\nEpoch: 81, Loss: 1.0926, Train: 68.25%, Valid: 67.66% Test: 65.66%\nEpoch: 82, Loss: 1.0876, Train: 68.49%, Valid: 68.35% Test: 67.21%\nEpoch: 83, Loss: 1.0812, Train: 68.47%, Valid: 68.26% Test: 67.07%\nEpoch: 84, Loss: 1.0833, Train: 68.53%, Valid: 68.13% Test: 66.27%\nEpoch: 85, Loss: 1.0790, Train: 68.76%, Valid: 68.43% Test: 67.25%\nEpoch: 86, Loss: 1.0718, Train: 68.75%, Valid: 68.49% Test: 67.36%\nEpoch: 87, Loss: 1.0733, Train: 68.70%, Valid: 68.46% Test: 66.73%\nEpoch: 88, Loss: 1.0708, Train: 68.85%, Valid: 68.40% Test: 66.90%\nEpoch: 89, Loss: 1.0653, Train: 68.90%, Valid: 68.67% Test: 67.69%\nEpoch: 90, Loss: 1.0653, Train: 68.91%, Valid: 68.28% Test: 66.50%\nEpoch: 91, Loss: 1.0628, Train: 69.11%, Valid: 68.58% Test: 67.17%\nEpoch: 92, Loss: 1.0581, Train: 69.02%, Valid: 69.07% Test: 68.46%\nEpoch: 93, Loss: 1.0598, Train: 68.83%, Valid: 67.18% Test: 64.59%\nEpoch: 94, Loss: 1.0624, Train: 68.72%, Valid: 68.91% Test: 68.51%\nEpoch: 95, Loss: 1.0657, Train: 68.03%, Valid: 66.88% Test: 64.38%\nEpoch: 96, Loss: 1.0886, Train: 67.04%, Valid: 67.74% Test: 67.56%\nEpoch: 97, Loss: 1.1177, Train: 67.71%, Valid: 66.37% Test: 63.81%\nEpoch: 98, Loss: 1.0998, Train: 69.22%, Valid: 69.13% Test: 68.10%\nEpoch: 99, Loss: 1.0503, Train: 68.62%, Valid: 68.72% Test: 67.86%\nEpoch: 100, Loss: 1.0645, Train: 68.31%, Valid: 66.85% Test: 64.24%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Question 5: What are your `best_model` validation and test accuracies?(20 points)\n\nRun the cell below to see the results of your best of model and save your model's predictions to a file named *ogbn-arxiv_node.csv*.\n\nYou can view this file by clicking on the *Folder* icon on the left side pannel. As in Colab 1, when you sumbit your assignment, you will have to download this file and attatch it to your submission.","metadata":{"id":"dQtt-EKA8P4r"}},{"cell_type":"code","source":"if 'IS_GRADESCOPE_ENV' not in os.environ:\n  best_result = test(best_model, data, split_idx, evaluator, save_model_results=True)\n  train_acc, valid_acc, test_acc = best_result\n  print(f'Best model: '\n        f'Train: {100 * train_acc:.2f}%, '\n        f'Valid: {100 * valid_acc:.2f}% '\n        f'Test: {100 * test_acc:.2f}%')","metadata":{"id":"EqcextqOL2FX","execution":{"iopub.status.busy":"2024-02-14T20:09:33.857523Z","iopub.execute_input":"2024-02-14T20:09:33.857917Z","iopub.status.idle":"2024-02-14T20:09:34.021485Z","shell.execute_reply.started":"2024-02-14T20:09:33.857886Z","shell.execute_reply":"2024-02-14T20:09:34.020517Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Saving Model Predictions\nBest model: Train: 69.22%, Valid: 69.13% Test: 68.10%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4) GNN: Graph Property Prediction\n\nIn this section we will create a graph neural network for graph property prediction (graph classification).\n","metadata":{"id":"R8pOD6y80TyI"}},{"cell_type":"markdown","source":"## Load and preprocess the dataset","metadata":{"id":"vRg5VOEdQTa4"}},{"cell_type":"code","source":"from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\nfrom torch_geometric.data import DataLoader\nfrom tqdm.notebook import tqdm\n\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  # Load the dataset\n  dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n\n  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n  print('Device: {}'.format(device))\n\n  split_idx = dataset.get_idx_split()\n\n  # Check task type\n  print('Task type: {}'.format(dataset.task_type))","metadata":{"id":"LXb-O5QUIgTH","execution":{"iopub.status.busy":"2024-02-14T20:09:38.733007Z","iopub.execute_input":"2024-02-14T20:09:38.733375Z","iopub.status.idle":"2024-02-14T20:09:48.683586Z","shell.execute_reply.started":"2024-02-14T20:09:38.733347Z","shell.execute_reply":"2024-02-14T20:09:48.682546Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\n","output_type":"stream"},{"name":"stderr","text":"Downloaded 0.00 GB: 100%|██████████| 3/3 [00:03<00:00,  1.01s/it]\nProcessing...\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/hiv.zip\nLoading necessary files...\nThis might take a while.\nProcessing graphs...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 41127/41127 [00:00<00:00, 66388.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Converting graphs into PyG objects...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 41127/41127 [00:02<00:00, 15749.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saving...\nDevice: cuda\nTask type: binary classification\n","output_type":"stream"},{"name":"stderr","text":"Done!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the dataset splits into corresponding dataloaders\n# We will train the graph classification task on a batch of 32 graphs\n# Shuffle the order of graphs for training set\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n  valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n  test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)","metadata":{"id":"7cHHbgW1c5hi","execution":{"iopub.status.busy":"2024-02-14T20:09:48.685867Z","iopub.execute_input":"2024-02-14T20:09:48.686320Z","iopub.status.idle":"2024-02-14T20:09:48.701660Z","shell.execute_reply.started":"2024-02-14T20:09:48.686286Z","shell.execute_reply":"2024-02-14T20:09:48.700595Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"}]},{"cell_type":"code","source":"if 'IS_GRADESCOPE_ENV' not in os.environ:\n  # Please do not change the args\n  args = {\n      'device': device,\n      'num_layers': 5,\n      'hidden_dim': 256,\n      'dropout': 0.5,\n      'lr': 0.001,\n      'epochs': 30,\n  }\n  args","metadata":{"id":"AYrSnOj0Y4DK","execution":{"iopub.status.busy":"2024-02-14T20:09:48.702855Z","iopub.execute_input":"2024-02-14T20:09:48.703147Z","iopub.status.idle":"2024-02-14T20:09:48.716511Z","shell.execute_reply.started":"2024-02-14T20:09:48.703123Z","shell.execute_reply":"2024-02-14T20:09:48.715691Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Graph Prediction Model","metadata":{"id":"7WLhguSTeazy"}},{"cell_type":"markdown","source":"### Graph Mini-Batching\nBefore diving into the actual model, we introduce the concept of mini-batching with graphs. In order to parallelize the processing of a mini-batch of graphs, PyG combines the graphs into a single disconnected graph data object (*torch_geometric.data.Batch*). *torch_geometric.data.Batch* inherits from *torch_geometric.data.Data* (introduced earlier) and contains an additional attribute called `batch`.\n\nThe `batch` attribute is a vector mapping each node to the index of its corresponding graph within the mini-batch:\n\n    batch = [0, ..., 0, 1, ..., n - 2, n - 1, ..., n - 1]\n\nThis attribute is crucial for associating which graph each node belongs to and can be used to e.g. average the node embeddings for each graph individually to compute graph level embeddings.\n\n","metadata":{"id":"u05Z14TRYPGn"}},{"cell_type":"markdown","source":"### Implemention\nNow, we have all of the tools to implement a GCN Graph Prediction model!  \n\nWe will reuse the existing GCN model to generate `node_embeddings` and then use  `Global Pooling` over the nodes to create graph level embeddings that can be used to predict properties for the each graph. Remeber that the `batch` attribute will be essential for performining Global Pooling over our mini-batch of graphs.","metadata":{"id":"Pcic9NNU3nGK"}},{"cell_type":"code","source":"from ogb.graphproppred.mol_encoder import AtomEncoder\nfrom torch_geometric.nn import global_add_pool, global_mean_pool\n\n### GCN to predict graph property\nclass GCN_Graph(torch.nn.Module):\n    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n        super(GCN_Graph, self).__init__()\n\n        # Load encoders for Atoms in molecule graphs\n        self.node_encoder = AtomEncoder(hidden_dim)\n\n        # Node embedding model\n        # Note that the input_dim and output_dim are set to hidden_dim\n        self.gnn_node = GCN(hidden_dim, hidden_dim,\n            hidden_dim, num_layers, dropout, return_embeds=True)\n\n        self.pool = global_mean_pool\n\n        # Output layer\n        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n\n\n    def reset_parameters(self):\n      self.gnn_node.reset_parameters()\n      self.linear.reset_parameters()\n\n    def forward(self, batched_data):\n        # TODO: Implement a function that takes as input a\n        # mini-batch of graphs (torch_geometric.data.Batch) and\n        # returns the predicted graph property for each graph.\n        #\n        # NOTE: Since we are predicting graph level properties,\n        # your output will be a tensor with dimension equaling\n        # the number of graphs in the mini-batch\n\n\n        # Extract important attributes of our mini-batch\n        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n        \n        embed = self.node_encoder(x)\n        out = self.gnn_node(embed, edge_index) \n        out = self.pool(out, batch) \n        out = self.linear(out)\n\n        return out","metadata":{"id":"3_Kq3zyjeZ22","execution":{"iopub.status.busy":"2024-02-14T20:09:50.061070Z","iopub.execute_input":"2024-02-14T20:09:50.061468Z","iopub.status.idle":"2024-02-14T20:09:50.073475Z","shell.execute_reply.started":"2024-02-14T20:09:50.061437Z","shell.execute_reply":"2024-02-14T20:09:50.072408Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def train(model, device, data_loader, optimizer, loss_fn):\n    # TODO: Implement a function that trains your model by\n    # using the given optimizer and loss_fn.\n    model.train()\n    loss = 0\n\n    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n      batch = batch.to(device)\n\n      if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n          pass\n      else:\n        ## ignore nan targets (unlabeled) when computing training loss.\n        is_labeled = batch.y == batch.y\n        is_labeled = is_labeled.to(torch.int).sequeeze()\n        \n        optimizer.zero_grad() \n        out = model(batch)\n        loss = loss_fn(batch.y[is_labeled].sequeeze().to(torch.float32)\n                       , out[is_labeled].squeeze())\n\n        loss.backward()\n        optimizer.step()\n\n    return loss.item()","metadata":{"id":"FJjnGuMSbjX0","execution":{"iopub.status.busy":"2024-02-14T20:09:54.143512Z","iopub.execute_input":"2024-02-14T20:09:54.143891Z","iopub.status.idle":"2024-02-14T20:09:54.151736Z","shell.execute_reply.started":"2024-02-14T20:09:54.143862Z","shell.execute_reply":"2024-02-14T20:09:54.150858Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# The evaluation function\ndef eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n    model.eval()\n    y_true = []\n    y_pred = []\n\n    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n        batch = batch.to(device)\n\n        if batch.x.shape[0] == 1:\n            pass\n        else:\n            with torch.no_grad():\n                pred = model(batch)\n\n            y_true.append(batch.y.view(pred.shape).detach().cpu())\n            y_pred.append(pred.detach().cpu())\n\n    y_true = torch.cat(y_true, dim = 0).numpy()\n    y_pred = torch.cat(y_pred, dim = 0).numpy()\n\n    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n\n    if save_model_results:\n        print (\"Saving Model Predictions\")\n\n        # Create a pandas dataframe with a two columns\n        # y_pred | y_true\n        data = {}\n        data['y_pred'] = y_pred.reshape(-1)\n        data['y_true'] = y_true.reshape(-1)\n\n        df = pd.DataFrame(data=data)\n        # Save to csv\n        df.to_csv('ogbg-molhiv_graph_' + save_file + '.csv', sep=',', index=False)\n\n    return evaluator.eval(input_dict)","metadata":{"id":"ztPHXq_Gzn7U","execution":{"iopub.status.busy":"2024-02-14T20:09:54.224208Z","iopub.execute_input":"2024-02-14T20:09:54.224733Z","iopub.status.idle":"2024-02-14T20:09:54.233730Z","shell.execute_reply.started":"2024-02-14T20:09:54.224709Z","shell.execute_reply":"2024-02-14T20:09:54.232887Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"if 'IS_GRADESCOPE_ENV' not in os.environ:\n  model = GCN_Graph(args['hidden_dim'],\n              dataset.num_tasks, args['num_layers'],\n              args['dropout']).to(device)\n  evaluator = Evaluator(name='ogbg-molhiv')","metadata":{"id":"MR1wQ4hMZeMw","execution":{"iopub.status.busy":"2024-02-14T20:09:55.028367Z","iopub.execute_input":"2024-02-14T20:09:55.029164Z","iopub.status.idle":"2024-02-14T20:09:55.050960Z","shell.execute_reply.started":"2024-02-14T20:09:55.029135Z","shell.execute_reply":"2024-02-14T20:09:55.050222Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Please do not change these args\n# Training should take <10min using GPU runtime\nimport copy\n\nif 'IS_GRADESCOPE_ENV' not in os.environ:\n  model.reset_parameters()\n\n  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n  loss_fn = torch.nn.BCEWithLogitsLoss()\n\n  best_model = None\n  best_valid_acc = 0\n\n  for epoch in range(1, 1 + args[\"epochs\"]):\n    print('Training...')\n    loss = train(model, device, train_loader, optimizer, loss_fn)\n\n    print('Evaluating...')\n    train_result = eval(model, device, train_loader, evaluator)\n    val_result = eval(model, device, valid_loader, evaluator)\n    test_result = eval(model, device, test_loader, evaluator)\n\n    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n    if valid_acc > best_valid_acc:\n        best_valid_acc = valid_acc\n        best_model = copy.deepcopy(model)\n    print(f'Epoch: {epoch:02d}, '\n          f'Loss: {loss:.4f}, '\n          f'Train: {100 * train_acc:.2f}%, '\n          f'Valid: {100 * valid_acc:.2f}% '\n          f'Test: {100 * test_acc:.2f}%')","metadata":{"id":"qJGTNZiuZy0A","execution":{"iopub.status.busy":"2024-02-14T20:09:55.187047Z","iopub.execute_input":"2024-02-14T20:09:55.187592Z","iopub.status.idle":"2024-02-14T20:20:45.949930Z","shell.execute_reply.started":"2024-02-14T20:09:55.187568Z","shell.execute_reply":"2024-02-14T20:20:45.949005Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fce32356c5a440493c08cc67561f126"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d13ff7425b541c6929be4729962a57d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4c85f438dfc49fba4b6b11db8d907c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f36922858fa74d39a304d807af4b1d5c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01, Loss: 0.6931, Train: 53.19%, Valid: 53.90% Test: 56.51%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef58570b4a77449692867e78ad020939"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"725207dcd64b4457a37b6f0be3ef2e5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6ce72b0a906473b8d3950e01913914f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d8200043ab24b208f3d0592f336d2eb"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02, Loss: 0.6931, Train: 58.39%, Valid: 52.39% Test: 47.21%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caafb71f28a54ce494e5c0497a0ee3ac"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d916b66886694fc38e558912fb6f6f68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ef133a8894b46d89de6f5cadbd12ed3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f78d6b9fd877485fa22224c0759e0798"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03, Loss: 0.6931, Train: 58.00%, Valid: 60.19% Test: 62.71%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99d19e9a18b3443b9c29eed6af786e9f"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a5a2a7e687a4f4e8b42b83558c290ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45e6729bafcc47f3bdd92ae83d3e59a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fae7a60c218340ccb9a5bc0f5d6c07cd"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04, Loss: 0.6931, Train: 60.74%, Valid: 65.72% Test: 65.80%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8175383803e94f1cac838c6f304f993d"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93b8bd2713b94029930c08a8b8974b14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b104db8d8dcb49488689b980645d3ae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33211c2596ff415db639e5114d61cfd6"}},"metadata":{}},{"name":"stdout","text":"Epoch: 05, Loss: 0.6931, Train: 62.92%, Valid: 65.81% Test: 65.03%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff71e7a46c214885a22c48c9482cf922"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8449e9fff8c4b55b88ce145d1622613"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf14e74786f64995813fad93221d3c99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed6235ea36fd4481849a3684ecd96052"}},"metadata":{}},{"name":"stdout","text":"Epoch: 06, Loss: 0.6931, Train: 64.38%, Valid: 65.58% Test: 65.44%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db08aa218a154b1f958996625b90ea19"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4269b8f614a4570b8c69e066975d478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e3dd0b3ddf94971bb79fe0bc4ae8f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b5e12761dea4f86ac10136e8515c1ff"}},"metadata":{}},{"name":"stdout","text":"Epoch: 07, Loss: 0.6931, Train: 65.29%, Valid: 65.27% Test: 63.70%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a2dd37898684496bb6c40a1070b4909"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c660af1cbde4d799d934fe93976d66c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dabb2e07ed4469998298edc0f3c9e03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dfe40a600a74c3e87a60087e36c387c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 08, Loss: 0.6931, Train: 67.67%, Valid: 68.89% Test: 66.41%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e6304b87c8146738ae8f19d0681d842"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c4e57912b4b4c8797787b1c6299230c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e66d1822d481437db8d1f36a09e9d96c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d947142440e340028c92dcf1b3349b25"}},"metadata":{}},{"name":"stdout","text":"Epoch: 09, Loss: 0.6931, Train: 67.81%, Valid: 70.52% Test: 66.03%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6367edd4ac9a4219bd8c587b91b30288"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfe366fac03746a7b2eb906f2b460f60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"559ff4be970344ca9ee4062c2f76ef0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85702397a05d4103aa9ab4584771bf28"}},"metadata":{}},{"name":"stdout","text":"Epoch: 10, Loss: 0.6931, Train: 64.67%, Valid: 70.04% Test: 68.47%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5673a8adbf8745d58853b30f72d0818c"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8087a278cb954ca4b7dda83fae0d2b35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc33434a3564bfe965ed615c4c5d129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe64766ded047f3abaaec883128b99f"}},"metadata":{}},{"name":"stdout","text":"Epoch: 11, Loss: 0.6931, Train: 67.49%, Valid: 74.41% Test: 68.23%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16251ac51ede40f786575e62f05b36bf"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1f9e71d31ab46cbbd70f5fb06e9663a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e3251d3b314bf88a7b8f7893c46907"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e58b6bdfefd4954abaa77bc1d22aba9"}},"metadata":{}},{"name":"stdout","text":"Epoch: 12, Loss: 0.6931, Train: 69.30%, Valid: 72.86% Test: 67.13%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d7383c30c6f4a2ab7f15024371d27db"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cfa0b212f8b43c197d96184b8449772"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cdaa10b7a51406abd5cb6a4d40baea9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fab638153b7c4bfa925d95ef27f6a279"}},"metadata":{}},{"name":"stdout","text":"Epoch: 13, Loss: 0.6931, Train: 68.16%, Valid: 71.43% Test: 69.85%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7032e721b244c598b2aa79ce9964ea3"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ea012812b34bb49fedcee13a976c3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b16ece3920a4e1ba10f3ceadb5827d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e18e67dc12c447669fc44c3b5490d57c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 14, Loss: 0.6931, Train: 69.49%, Valid: 71.74% Test: 69.65%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"189c0e93b4414e4f8b28fc5c5d8aea80"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8804bf92d9e942c297d54d3c3ec25174"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7c50fb7bc3b4119a0505a44ed8f14a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d01e97c18e74f0b968c13bea724a9d8"}},"metadata":{}},{"name":"stdout","text":"Epoch: 15, Loss: 0.6931, Train: 69.76%, Valid: 68.98% Test: 70.29%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"852d45c0b0414ac2b39aaee0fb3bedf9"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b5dfb91bf84a068b410965fa182233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffeb48d0afee4b97852b0eaa29d82859"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fba18c3005f4b1c8d025fc770f8c37a"}},"metadata":{}},{"name":"stdout","text":"Epoch: 16, Loss: 0.6931, Train: 68.28%, Valid: 69.68% Test: 65.94%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697b056d0a6d4fc7a84de485caa3ac42"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f05063e57f824ad3a8e425681e6c93a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b39d4d83c89f43699fc1085c0478de76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f61e157b94244f38d857ed00b12f680"}},"metadata":{}},{"name":"stdout","text":"Epoch: 17, Loss: 0.6931, Train: 69.29%, Valid: 72.09% Test: 68.68%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0207ebef162942f186b9fce678973207"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a43f01ebb9145bc8e853bffd4415587"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bcb144c41384eb992fa397675d1633a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e95bd32b8734e08bd3b1475749c3fdf"}},"metadata":{}},{"name":"stdout","text":"Epoch: 18, Loss: 0.6931, Train: 70.75%, Valid: 72.82% Test: 70.06%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"181f50bc74054b2fbe9a08f8fdec8dbe"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14013284c8d470087c6bb4194a5ee1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5474f183d3d440983a7adf2e84c610d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989aa6078b834b40bbfd4caf1108a6c1"}},"metadata":{}},{"name":"stdout","text":"Epoch: 19, Loss: 0.6931, Train: 70.22%, Valid: 71.82% Test: 69.38%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dd1054a1ac94eac9461297cf4f46bdb"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e7915d74ff04b7c80a5efe058681bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62641c8c997b4a68855b6f6811a20639"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"371bb25587434daf900b88acbf27e312"}},"metadata":{}},{"name":"stdout","text":"Epoch: 20, Loss: 0.6931, Train: 69.84%, Valid: 68.45% Test: 68.87%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e49d27cf0be14749aea179c55d19eb97"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e4034548c5f45b28736051b6c0af722"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af5a22dea214862af9b70b7c0dc0069"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22dd1dd8f1ab4327b344ffd7aa38b367"}},"metadata":{}},{"name":"stdout","text":"Epoch: 21, Loss: 0.6931, Train: 70.81%, Valid: 69.20% Test: 68.73%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51606dd80d8f4062b2f2744ed54658a8"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2030cc8708034fb494873d6e10cd1e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f7d3c79e49941668d02c54a6a88ef36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53d0769fac34763985cc40e1e738612"}},"metadata":{}},{"name":"stdout","text":"Epoch: 22, Loss: 0.6931, Train: 69.33%, Valid: 68.82% Test: 66.42%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98d2c8cf620f4b2683cb1fae259d515a"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d488c167bee84df6980c1ce6470a0aa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"797aba2a4868446185f23718640ea8b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c8714982b4c4c37a397c0f56117c196"}},"metadata":{}},{"name":"stdout","text":"Epoch: 23, Loss: 0.6931, Train: 70.49%, Valid: 69.85% Test: 66.74%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"959ce27899764912a7f1d183acda6524"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87decd3b53994bf4a71a5454f1f2f36b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7397930ea12f4cbf92d8862172cbc5c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f75b4242fd04faa943936d0310c9a18"}},"metadata":{}},{"name":"stdout","text":"Epoch: 24, Loss: 0.6931, Train: 71.20%, Valid: 70.06% Test: 68.99%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f7b5e4bb43d4037ab1938df7ad9a296"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34f1b936939b4e55b0f1b2620d63df76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"822a0606ef2046d6b9e468d3dbcfea28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd34ce18caca409fbc2768bdf614a0d4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 25, Loss: 0.6931, Train: 71.44%, Valid: 69.87% Test: 67.75%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae601dc87ec44d85b778c08b9c698035"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e224b061088647a7b8b54eb3eb97dc66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53048d3047ce429a9af4c02d0a45afe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4381fe950fdb40dc96d19c6ccd8f90e9"}},"metadata":{}},{"name":"stdout","text":"Epoch: 26, Loss: 0.6931, Train: 69.87%, Valid: 71.70% Test: 67.79%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5863cc1fb2d40edbbbd6896be9d77d9"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6ac62b4944449a68de2fd8150e93cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcd818d27aad4e1c88521e77ea36e6c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed6d05a007d94829bacc9c08df862bab"}},"metadata":{}},{"name":"stdout","text":"Epoch: 27, Loss: 0.6931, Train: 71.46%, Valid: 68.58% Test: 65.31%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf8cbefe6adf4b5c8ab15b7b19b9efba"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22436997058d4348a10acad900804c0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e623db1049443bad7784e8a92c0d5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8389e1814ea482284cdca21574f76dc"}},"metadata":{}},{"name":"stdout","text":"Epoch: 28, Loss: -8003597.5000, Train: 69.86%, Valid: 70.33% Test: 64.99%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7f11e24d9ac4bd2bb46504f2ced2766"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75e31d37b13744b28ddd3bd2a1d66cba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cacec9b86874cb2ab1ce393e371f92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a37d1d5d4de24f6b896f6a975d97d93c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 29, Loss: 0.6931, Train: 71.96%, Valid: 69.41% Test: 67.05%\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d946a5e5c1f44e79879aa4c83d62751d"}},"metadata":{}},{"name":"stdout","text":"Evaluating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0dc6a1137bc46ada0dfd40d3da76dc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14005ae6d63b4f759b973c00197b0d32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72703b9493544dbfb474a56fc60b8194"}},"metadata":{}},{"name":"stdout","text":"Epoch: 30, Loss: 0.6931, Train: 71.59%, Valid: 66.24% Test: 64.79%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Question 6: What are your `best_model` validation and test ROC-AUC scores? (20 points)\n\nRun the cell below to see the results of your best of model and save your model's predictions over the validation and test datasets. The resulting files are named *ogbn-arxiv_graph_valid.csv* and *ogbn-arxiv_graph_test.csv*.\n\nAgain, you can view these files by clicking on the *Folder* icon on the left side pannel. As in Colab 1, when you sumbit your assignment, you will have to download these files and attatch them to your submission.","metadata":{"id":"6I17-Qso_n88"}},{"cell_type":"code","source":"if 'IS_GRADESCOPE_ENV' not in os.environ:\n  train_acc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n  valid_acc = eval(best_model, device, valid_loader, evaluator, save_model_results=True, save_file=\"valid\")[dataset.eval_metric]\n  test_acc  = eval(best_model, device, test_loader, evaluator, save_model_results=True, save_file=\"test\")[dataset.eval_metric]\n\n  print(f'Best model: '\n      f'Train: {100 * train_acc:.2f}%, '\n      f'Valid: {100 * valid_acc:.2f}% '\n      f'Test: {100 * test_acc:.2f}%')","metadata":{"id":"Oq5QaG21dOOO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Question 7 (Optional): Experiment with the two other global pooling layers in Pytorch Geometric.","metadata":{"id":"gBi_t8n0iZ4P"}},{"cell_type":"markdown","source":"# Submission\n\nTo submit Colab 2, please submit to the following assignments on Gradescope:\n\n1. \"Colab 2\": submit your answers to the questions in this assignment\n2. \"Colab 2 Code\": submit your completed *CS224W_Colab2.ipynb*. From the \"File\" menu select \"Download .ipynb\" to save a local copy of your completed Colab. **PLEASE DO NOT CHANGE THE NAME!** The autograder depends on the .ipynb file being called \"CS224W_Colab2.ipynb\".","metadata":{"id":"e7JXsMTBgeOI"}},{"cell_type":"code","source":"","metadata":{"id":"L3Q5WmndEnAJ"},"execution_count":null,"outputs":[]}]}